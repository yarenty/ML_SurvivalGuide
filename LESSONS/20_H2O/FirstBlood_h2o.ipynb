{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "H2O [Generalized Linear Model](https://en.wikipedia.org/wiki/Generalized_linear_model) model can be used to do supervised classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pandas",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f09ae378f571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pandas"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_161\"; Java(TM) SE Runtime Environment (build 1.8.0_161-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)\n",
      "  Starting server from /usr/local/lib/python3.5/dist-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpcbwp5um6\n",
      "  JVM stdout: /tmp/tmpcbwp5um6/h2o_yarenty_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpcbwp5um6/h2o_yarenty_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54323\n",
      "Connecting to H2O server at http://127.0.0.1:54323... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>09 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Dublin</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.18.0.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>5 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_yarenty_vlfa2f</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.778 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54323</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         09 secs\n",
       "H2O cluster timezone:       Europe/Dublin\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.18.0.4\n",
       "H2O cluster version age:    5 days\n",
       "H2O cluster name:           H2O_from_python_yarenty_vlfa2f\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.778 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54323\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.5.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.init(max_mem_size = \"2G\")             #specify max number of bytes. uses all cores by default.\\n\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package h2o:\n",
      "\n",
      "NAME\n",
      "    h2o - :mod:`h2o` -- module for using H2O services.\n",
      "\n",
      "DESCRIPTION\n",
      "    (please add description).\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    assembly\n",
      "    astfun\n",
      "    automl (package)\n",
      "    backend (package)\n",
      "    cross_validation\n",
      "    demos\n",
      "    display\n",
      "    estimators (package)\n",
      "    exceptions\n",
      "    expr\n",
      "    expr_optimizer\n",
      "    frame\n",
      "    grid (package)\n",
      "    group_by\n",
      "    h2o\n",
      "    job\n",
      "    model (package)\n",
      "    schemas (package)\n",
      "    transforms (package)\n",
      "    two_dim_table\n",
      "    utils (package)\n",
      "\n",
      "SUBMODULES\n",
      "    __init__\n",
      "\n",
      "FUNCTIONS\n",
      "    api(endpoint, data=None, json=None, filename=None, save_to=None)\n",
      "        Perform a REST API request to a previously connected server.\n",
      "        \n",
      "        This function is mostly for internal purposes, but may occasionally be useful for direct access to\n",
      "        the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`.\n",
      "    \n",
      "    as_list(data, use_pandas=True, header=True)\n",
      "        Convert an H2O data object into a python-specific object.\n",
      "        \n",
      "        WARNING! This will pull all data local!\n",
      "        \n",
      "        If Pandas is available (and use_pandas is True), then pandas will be used to parse the\n",
      "        data frame. Otherwise, a list-of-lists populated by character data will be returned (so\n",
      "        the types of data will all be str).\n",
      "        \n",
      "        :param data: an H2O data object.\n",
      "        :param use_pandas: If True, try to use pandas for reading in the data.\n",
      "        :param header: If True, return column names as first element in list\n",
      "        \n",
      "        :returns: List of lists (Rows x Columns).\n",
      "    \n",
      "    assign(data, xid)\n",
      "        (internal) Assign new id to the frame.\n",
      "        \n",
      "        :param data: an H2OFrame whose id should be changed\n",
      "        :param xid: new id for the frame.\n",
      "        :returns: the passed frame.\n",
      "    \n",
      "    cluster()\n",
      "        Return :class:`H2OCluster` object describing the backend H2O cloud.\n",
      "    \n",
      "    cluster_info(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().show_status()``.\n",
      "    \n",
      "    cluster_status(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().show_status(True)``.\n",
      "    \n",
      "    connect(server=None, url=None, ip=None, port=None, https=None, verify_ssl_certificates=None, auth=None, proxy=None, cookies=None, verbose=True, config=None)\n",
      "        Connect to an existing H2O server, remote or local.\n",
      "        \n",
      "        There are two ways to connect to a server: either pass a `server` parameter containing an instance of\n",
      "        an H2OLocalServer, or specify `ip` and `port` of the server that you want to connect to.\n",
      "        \n",
      "        :param server: An H2OLocalServer instance to connect to (optional).\n",
      "        :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n",
      "        :param ip: The ip address (or host name) of the server where H2O is running.\n",
      "        :param port: Port number that H2O service is listening to.\n",
      "        :param https: Set to True to connect via https:// instead of http://.\n",
      "        :param verify_ssl_certificates: When using https, setting this to False will disable SSL certificates verification.\n",
      "        :param auth: Either a (username, password) pair for basic authentication, or one of the requests.auth\n",
      "                     authenticator objects.\n",
      "        :param proxy: Proxy server address.\n",
      "        :param cookies: Cookie (or list of) to add to request\n",
      "        :param verbose: Set to False to disable printing connection status messages.\n",
      "        :param connection_conf: Connection configuration object encapsulating connection parameters.\n",
      "        :returns: the new :class:`H2OConnection` object.\n",
      "    \n",
      "    connection()\n",
      "        Return the current :class:`H2OConnection` handler.\n",
      "    \n",
      "    create_frame(frame_id=None, rows=10000, cols=10, randomize=True, real_fraction=None, categorical_fraction=None, integer_fraction=None, binary_fraction=None, time_fraction=None, string_fraction=None, value=0, real_range=100, factors=100, integer_range=100, binary_ones_fraction=0.02, missing_fraction=0.01, has_response=False, response_factors=2, positive_response=False, seed=None, seed_for_column_types=None)\n",
      "        Create a new frame with random data.\n",
      "        \n",
      "        Creates a data frame in H2O with real-valued, categorical, integer, and binary columns specified by the user.\n",
      "        \n",
      "        :param frame_id: the destination key. If empty, this will be auto-generated.\n",
      "        :param rows: the number of rows of data to generate.\n",
      "        :param cols: the number of columns of data to generate. Excludes the response column if has_response is True.\n",
      "        :param randomize: If True, data values will be randomly generated. This must be True if either\n",
      "            categorical_fraction or integer_fraction is non-zero.\n",
      "        :param value: if randomize is False, then all real-valued entries will be set to this value.\n",
      "        :param real_range: the range of randomly generated real values.\n",
      "        :param real_fraction: the fraction of columns that are real-valued.\n",
      "        :param categorical_fraction: the fraction of total columns that are categorical.\n",
      "        :param factors: the number of (unique) factor levels in each categorical column.\n",
      "        :param integer_fraction: the fraction of total columns that are integer-valued.\n",
      "        :param integer_range: the range of randomly generated integer values.\n",
      "        :param binary_fraction: the fraction of total columns that are binary-valued.\n",
      "        :param binary_ones_fraction: the fraction of values in a binary column that are set to 1.\n",
      "        :param time_fraction: the fraction of randomly created date/time columns.\n",
      "        :param string_fraction: the fraction of randomly created string columns.\n",
      "        :param missing_fraction: the fraction of total entries in the data frame that are set to NA.\n",
      "        :param has_response: A logical value indicating whether an additional response column should be prepended to the\n",
      "            final H2O data frame. If set to True, the total number of columns will be ``cols + 1``.\n",
      "        :param response_factors: if has_response is True, then this variable controls the type of the \"response\" column:\n",
      "            setting response_factors to 1 will generate real-valued response, any value greater or equal than 2 will\n",
      "            create categorical response with that many categories.\n",
      "        :param positive_reponse: when response variable is present and of real type, this will control whether it\n",
      "            contains positive values only, or both positive and negative.\n",
      "        :param seed: a seed used to generate random values when ``randomize`` is True.\n",
      "        :param seed_for_column_types: a seed used to generate random column types when ``randomize`` is True.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` object\n",
      "    \n",
      "    deep_copy(data, xid)\n",
      "        Create a deep clone of the frame ``data``.\n",
      "        \n",
      "        :param data: an H2OFrame to be cloned\n",
      "        :param xid: (internal) id to be assigned to the new frame.\n",
      "        :returns: new :class:`H2OFrame` which is the clone of the passed frame.\n",
      "    \n",
      "    demo(funcname, interactive=True, echo=True, test=False)\n",
      "        H2O built-in demo facility.\n",
      "        \n",
      "        :param funcname: A string that identifies the h2o python function to demonstrate.\n",
      "        :param interactive: If True, the user will be prompted to continue the demonstration after every segment.\n",
      "        :param echo: If True, the python commands that are executed will be displayed.\n",
      "        :param test: If True, `h2o.init()` will not be called (used for pyunit testing).\n",
      "        \n",
      "        :example:\n",
      "            >>> import h2o\n",
      "            >>> h2o.demo(\"gbm\")\n",
      "    \n",
      "    download_all_logs(dirname='.', filename=None)\n",
      "        Download H2O log files to disk.\n",
      "        \n",
      "        :param dirname: a character string indicating the directory that the log file should be saved in.\n",
      "        :param filename: a string indicating the name that the CSV file should be. Note that the saved format is .zip, so the file name must include the .zip extension.\n",
      "        \n",
      "        :returns: path of logs written in a zip file.\n",
      "        \n",
      "        :examples: The following code will save the zip file `'autoh2o_log.zip'` in a directory that is one down from where you are currently working into a directory called `your_directory_name`. (Please note that `your_directory_name` should be replaced with the name of the directory that you've created and that already exists.)\n",
      "        \n",
      "            >>> h2o.download_all_logs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')\n",
      "    \n",
      "    download_csv(data, filename)\n",
      "        Download an H2O data set to a CSV file on the local disk.\n",
      "        \n",
      "        Warning: Files located on the H2O server may be very large! Make sure you have enough\n",
      "        hard drive space to accommodate the entire file.\n",
      "        \n",
      "        :param data: an H2OFrame object to be downloaded.\n",
      "        :param filename: name for the CSV file where the data should be saved to.\n",
      "    \n",
      "    download_pojo(model, path='', get_jar=True, jar_name='')\n",
      "        Download the POJO for this model to the directory specified by path; if path is \"\", then dump to screen.\n",
      "        \n",
      "        :param model: the model whose scoring POJO should be retrieved.\n",
      "        :param path: an absolute path to the directory where POJO should be saved.\n",
      "        :param get_jar: retrieve the h2o-genmodel.jar also (will be saved to the same folder ``path``).\n",
      "        :param jar_name: Custom name of genmodel jar.\n",
      "        :returns: location of the downloaded POJO file.\n",
      "    \n",
      "    enable_expr_optimizations(flag)\n",
      "        Enable expression tree local optimizations.\n",
      "    \n",
      "    export_file(frame, path, force=False, parts=1)\n",
      "        Export a given H2OFrame to a path on the machine this python session is currently connected to.\n",
      "        \n",
      "        :param frame: the Frame to save to disk.\n",
      "        :param path: the path to the save point on disk.\n",
      "        :param force: if True, overwrite any preexisting file with the same path\n",
      "        :param parts: enables export to multiple 'part' files instead of just a single file.\n",
      "            Convenient for large datasets that take too long to store in a single file.\n",
      "            Use parts=-1 to instruct H2O to determine the optimal number of part files or\n",
      "            specify your desired maximum number of part files. Path needs to be a directory\n",
      "            when exporting to multiple files, also that directory must be empty.\n",
      "            Default is ``parts = 1``, which is to export to a single file.\n",
      "    \n",
      "    flow()\n",
      "        Open H2O Flow in your browser.\n",
      "    \n",
      "    frame(frame_id)\n",
      "        Retrieve metadata for an id that points to a Frame.\n",
      "        \n",
      "        :param frame_id: the key of a Frame in H2O.\n",
      "        \n",
      "        :returns: dict containing the frame meta-information.\n",
      "    \n",
      "    frames()\n",
      "        Retrieve all the Frames.\n",
      "        \n",
      "        :returns: Meta information on the frames\n",
      "    \n",
      "    get_frame(frame_id, **kwargs)\n",
      "        Obtain a handle to the frame in H2O with the frame_id key.\n",
      "        \n",
      "        :param str frame_id: id of the frame to retrieve.\n",
      "        :returns: an :class:`H2OFrame` object\n",
      "    \n",
      "    get_grid(grid_id)\n",
      "        Return the specified grid.\n",
      "        \n",
      "        :param grid_id: The grid identification in h2o\n",
      "        \n",
      "        :returns: an :class:`H2OGridSearch` instance.\n",
      "    \n",
      "    get_model(model_id)\n",
      "        Load a model from the server.\n",
      "        \n",
      "        :param model_id: The model identification in H2O\n",
      "        \n",
      "        :returns: Model object, a subclass of H2OEstimator\n",
      "    \n",
      "    get_timezone(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().timezone``.\n",
      "    \n",
      "    import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None, na_strings=None, pattern=None)\n",
      "        Import a dataset that is already on the cluster.\n",
      "        \n",
      "        The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n",
      "        cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n",
      "        multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n",
      "        the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n",
      "        If you running H2O server on your own maching, then both methods behave the same.\n",
      "        \n",
      "        :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n",
      "        :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n",
      "            automatically generated.\n",
      "        :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param sep: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param col_names: A list of column names for the file.\n",
      "        :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n",
      "            directory.\n",
      "        \n",
      "        :returns: a new :class:`H2OFrame` instance.\n",
      "        \n",
      "        :examples:\n",
      "            >>> # Single file import\n",
      "            >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n",
      "            >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n",
      "            >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n",
      "            ...                                pattern = \"iris_.*\\.csv\")\n",
      "    \n",
      "    import_sql_select(connection_url, select_query, username, password, optimize=True)\n",
      "        Import the SQL table that is the result of the specified SQL query to H2OFrame in memory.\n",
      "        \n",
      "        Creates a temporary SQL table from the specified sql_query.\n",
      "        Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.\n",
      "        Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n",
      "        \n",
      "          java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n",
      "        \n",
      "        Also see h2o.import_sql_table. Currently supported SQL databases are MySQL, PostgreSQL, and MariaDB. Support\n",
      "        for Oracle 12g and Microsoft SQL Server is forthcoming.\n",
      "        \n",
      "        :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n",
      "            Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n",
      "        :param select_query: SQL query starting with `SELECT` that returns rows from one or more database tables.\n",
      "        :param username: username for SQL server\n",
      "        :param password: password for SQL server\n",
      "        :param optimize: optimize import of SQL table for faster imports. Experimental.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` containing data of the specified SQL query.\n",
      "        \n",
      "        :examples:\n",
      "            >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n",
      "            >>> select_query = \"SELECT bikeid from citibike20k\"\n",
      "            >>> username = \"root\"\n",
      "            >>> password = \"abc123\"\n",
      "            >>> my_citibike_data = h2o.import_sql_select(conn_url, select_query,\n",
      "            ...                                          username, password)\n",
      "    \n",
      "    import_sql_table(connection_url, table, username, password, columns=None, optimize=True)\n",
      "        Import SQL table to H2OFrame in memory.\n",
      "        \n",
      "        Assumes that the SQL table is not being updated and is stable.\n",
      "        Runs multiple SELECT SQL queries concurrently for parallel ingestion.\n",
      "        Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n",
      "        \n",
      "            java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n",
      "        \n",
      "        Also see :func:`import_sql_select`.\n",
      "        Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, and Netezza. Support for Oracle 12g and Microsoft SQL\n",
      "        Server is forthcoming.\n",
      "        \n",
      "        :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n",
      "            Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n",
      "        :param table: name of SQL table\n",
      "        :param columns: a list of column names to import from SQL table. Default is to import all columns.\n",
      "        :param username: username for SQL server\n",
      "        :param password: password for SQL server\n",
      "        :param optimize: optimize import of SQL table for faster imports. Experimental.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` containing data of the specified SQL table.\n",
      "        \n",
      "        :examples:\n",
      "            >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n",
      "            >>> table = \"citibike20k\"\n",
      "            >>> username = \"root\"\n",
      "            >>> password = \"abc123\"\n",
      "            >>> my_citibike_data = h2o.import_sql_table(conn_url, table, username, password)\n",
      "    \n",
      "    init(url=None, ip=None, port=None, https=None, insecure=None, username=None, password=None, cookies=None, proxy=None, start_h2o=True, nthreads=-1, ice_root=None, enable_assertions=True, max_mem_size=None, min_mem_size=None, strict_version_check=None, ignore_config=False, extra_classpath=None, **kwargs)\n",
      "        Attempt to connect to a local server, or if not successful start a new server and connect to it.\n",
      "        \n",
      "        :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n",
      "        :param ip: The ip address (or host name) of the server where H2O is running.\n",
      "        :param port: Port number that H2O service is listening to.\n",
      "        :param https: Set to True to connect via https:// instead of http://.\n",
      "        :param insecure: When using https, setting this to True will disable SSL certificates verification.\n",
      "        :param username: Username and\n",
      "        :param password: Password for basic authentication.\n",
      "        :param cookies: Cookie (or list of) to add to each request.\n",
      "        :param proxy: Proxy server address.\n",
      "        :param start_h2o: If False, do not attempt to start an h2o server when connection to an existing one failed.\n",
      "        :param nthreads: \"Number of threads\" option when launching a new h2o server.\n",
      "        :param ice_root: Directory for temporary files for the new h2o server.\n",
      "        :param enable_assertions: Enable assertions in Java for the new h2o server.\n",
      "        :param max_mem_size: Maximum memory to use for the new h2o server.\n",
      "        :param min_mem_size: Minimum memory to use for the new h2o server.\n",
      "        :param strict_version_check: If True, an error will be raised if the client and server versions don't match.\n",
      "        :param ignore_config: Indicates whether a processing of a .h2oconfig file should be conducted or not. Default value is False.\n",
      "        :param extra_classpath: List of paths to libraries that should be included on the Java classpath when starting H2O from Python.\n",
      "        :param kwargs: (all other deprecated attributes)\n",
      "    \n",
      "    interaction(data, factors, pairwise, max_factors, min_occurrence, destination_frame=None)\n",
      "        Categorical Interaction Feature Creation in H2O.\n",
      "        \n",
      "        Creates a frame in H2O with n-th order interaction features between categorical columns, as specified by\n",
      "        the user.\n",
      "        \n",
      "        :param data: the H2OFrame that holds the target categorical columns.\n",
      "        :param factors: factor columns (either indices or column names).\n",
      "        :param pairwise: If True, create pairwise interactions between factors (otherwise create one\n",
      "            higher-order interaction). Only applicable if there are 3 or more factors.\n",
      "        :param max_factors: Max. number of factor levels in pair-wise interaction terms (if enforced, one extra\n",
      "            catch-all factor will be made).\n",
      "        :param min_occurrence: Min. occurrence threshold for factor levels in pair-wise interaction terms\n",
      "        :param destination_frame: a string indicating the destination key. If empty, this will be auto-generated by H2O.\n",
      "        \n",
      "        :returns: :class:`H2OFrame`\n",
      "    \n",
      "    is_expr_optimizations_enabled()\n",
      "    \n",
      "    lazy_import(path, pattern=None)\n",
      "        Import a single file or collection of files.\n",
      "        \n",
      "        :param path: A path to a data file (remote or local).\n",
      "        :param pattern: Character string containing a regular expression to match file(s) in the folder.\n",
      "        :returns: either a :class:`H2OFrame` with the content of the provided file, or a list of such frames if\n",
      "            importing multiple files.\n",
      "    \n",
      "    list_timezones(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().list_timezones()``.\n",
      "    \n",
      "    load_dataset(relative_path)\n",
      "        Imports a data file within the 'h2o_data' folder.\n",
      "    \n",
      "    load_model(path)\n",
      "        Load a saved H2O model from disk. (Note that ensemble binary models can now be loaded using this method.)\n",
      "        \n",
      "        :param path: the full path of the H2O Model to be imported.\n",
      "        \n",
      "        :returns: an :class:`H2OEstimator` object\n",
      "        \n",
      "        :examples:\n",
      "            >>> path = h2o.save_model(my_model, dir=my_path)\n",
      "            >>> h2o.load_model(path)\n",
      "    \n",
      "    log_and_echo(message='')\n",
      "        Log a message on the server-side logs.\n",
      "        \n",
      "        This is helpful when running several pieces of work one after the other on a single H2O\n",
      "        cluster and you want to make a notation in the H2O server side log where one piece of\n",
      "        work ends and the next piece of work begins.\n",
      "        \n",
      "        Sends a message to H2O for logging. Generally used for debugging purposes.\n",
      "        \n",
      "        :param message: message to write to the log.\n",
      "    \n",
      "    ls()\n",
      "        List keys on an H2O Cluster.\n",
      "    \n",
      "    make_metrics(predicted, actual, domain=None, distribution=None)\n",
      "        Create Model Metrics from predicted and actual values in H2O.\n",
      "        \n",
      "        :param H2OFrame predicted: an H2OFrame containing predictions.\n",
      "        :param H2OFrame actuals: an H2OFrame containing actual values.\n",
      "        :param domain: list of response factors for classification.\n",
      "        :param distribution: distribution for regression.\n",
      "    \n",
      "    network_test(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().network_test()``.\n",
      "    \n",
      "    no_progress()\n",
      "        Disable the progress bar from flushing to stdout.\n",
      "        \n",
      "        The completed progress bar is printed when a job is complete so as to demarcate a log file.\n",
      "    \n",
      "    parse_raw(setup, id=None, first_line_is_header=0)\n",
      "        Parse dataset using the parse setup structure.\n",
      "        \n",
      "        :param setup: Result of ``h2o.parse_setup()``\n",
      "        :param id: an id for the frame.\n",
      "        :param first_line_is_header: -1, 0, 1 if the first line is to be used as the header\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` object.\n",
      "    \n",
      "    parse_setup(raw_frames, destination_frame=None, header=0, separator=None, column_names=None, column_types=None, na_strings=None)\n",
      "        Retrieve H2O's best guess as to what the structure of the data file is.\n",
      "        \n",
      "        During parse setup, the H2O cluster will make several guesses about the attributes of\n",
      "        the data. This method allows a user to perform corrective measures by updating the\n",
      "        returning dictionary from this method. This dictionary is then fed into `parse_raw` to\n",
      "        produce the H2OFrame instance.\n",
      "        \n",
      "        :param raw_frames: a collection of imported file frames\n",
      "        :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will\n",
      "            automatically be generated.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param separator: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param column_names: A list of column names for the file.\n",
      "        :param column_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        \n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        \n",
      "        :returns: a dictionary containing parse parameters guessed by the H2O backend.\n",
      "    \n",
      "    rapids(expr)\n",
      "        Execute a Rapids expression.\n",
      "        \n",
      "        :param expr: The rapids expression (ascii string).\n",
      "        \n",
      "        :returns: The JSON response (as a python dictionary) of the Rapids execution.\n",
      "    \n",
      "    remove(x)\n",
      "        Remove object(s) from H2O.\n",
      "        \n",
      "        :param x: H2OFrame, H2OEstimator, or string, or a list of those things: the object(s) or unique id(s)\n",
      "            pointing to the object(s) to be removed.\n",
      "    \n",
      "    remove_all()\n",
      "        Remove all objects from H2O.\n",
      "    \n",
      "    save_model(model, path='', force=False)\n",
      "        Save an H2O Model object to disk. (Note that ensemble binary models can now be saved using this method.)\n",
      "        \n",
      "        :param model: The model object to save.\n",
      "        :param path: a path to save the model at (hdfs, s3, local)\n",
      "        :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      "        \n",
      "        :returns: the path of the saved model\n",
      "        \n",
      "        :examples:\n",
      "            >>> path = h2o.save_model(my_model, dir=my_path)\n",
      "    \n",
      "    set_timezone(*args, **kwargs)\n",
      "        Deprecated, set ``h2o.cluster().timezone`` instead.\n",
      "    \n",
      "    show_progress()\n",
      "        Enable the progress bar (it is enabled by default).\n",
      "    \n",
      "    shutdown(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "    \n",
      "    upload_custom_metric(func, func_file='metrics.py', func_name=None, class_name=None, source_provider=None)\n",
      "        Upload given metrics function into H2O cluster.\n",
      "        \n",
      "        The metrics can have different representation:\n",
      "          - method\n",
      "          - class: needs to inherit from water.udf.CFunc2 and implement method apply(actual, predict)\n",
      "          returning double\n",
      "          - string: the same as in class case, but the class is given as a string\n",
      "        \n",
      "        :param func:  metrics representation: string, class, function\n",
      "        :param func_file:  internal name of file to save given metrics representation\n",
      "        :param func_name:  name for h2o key under which the given metric is saved\n",
      "        :param class_name: name of class wrapping the metrics function\n",
      "        :param source_provider: a function which provides a source code for given function\n",
      "        :return: reference to uploaded metrics function\n",
      "    \n",
      "    upload_file(path, destination_frame=None, header=0, sep=None, col_names=None, col_types=None, na_strings=None)\n",
      "        Upload a dataset from the provided local path to the H2O cluster.\n",
      "        \n",
      "        Does a single-threaded push to H2O. Also see :meth:`import_file`.\n",
      "        \n",
      "        :param path: A path specifying the location of the data to upload.\n",
      "        :param destination_frame:  The unique hex key assigned to the imported file. If none is given, a key will\n",
      "            be automatically generated.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param sep: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param col_names: A list of column names for the file.\n",
      "        :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        \n",
      "        :returns: a new :class:`H2OFrame` instance.\n",
      "        \n",
      "        :examples:\n",
      "            >>> frame = h2o.upload_file(\"/path/to/local/data\")\n",
      "\n",
      "DATA\n",
      "    __all__ = ('connect', 'init', 'api', 'connection', 'upload_file', 'laz...\n",
      "    __buildinfo__ = \"versionFromGradle='3.18.0',projectVersion='3.18....il...\n",
      "\n",
      "VERSION\n",
      "    3.18.0.4\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.5/dist-packages/h2o/__init__.py\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGeneralizedLinearEstimator in module h2o.estimators.glm:\n",
      "\n",
      "class H2OGeneralizedLinearEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Generalized Linear Modeling\n",
      " |  \n",
      " |  Fits a generalized linear model, specified by a response variable, a set of predictors, and a\n",
      " |  description of the error distribution.\n",
      " |  \n",
      " |  A subclass of :class:`ModelBase` is returned. The specific subclass depends on the machine learning task\n",
      " |  at hand (if it's binomial classification, then an H2OBinomialModel is returned, if it's regression then a\n",
      " |  H2ORegressionModel is returned). The default print-out of the models is shown, but further GLM-specific\n",
      " |  information can be queried out of the object. Upon completion of the GLM, the resulting object has\n",
      " |  coefficients, normalized coefficients, residual/null deviance, aic, and a host of model metrics including\n",
      " |  MSE, AUC (for logistic regression), degrees of freedom, and confusion matrices.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGeneralizedLinearEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  getGLMRegularizationPath(model)\n",
      " |      Extract full regularization path explored during lambda search from glm model.\n",
      " |      \n",
      " |      :param model: source lambda search model\n",
      " |  \n",
      " |  makeGLMModel(model, coefs, threshold=0.5)\n",
      " |      Create a custom GLM model using the given coefficients.\n",
      " |      \n",
      " |      Needs to be passed source model trained on the dataset to extract the dataset information from.\n",
      " |      \n",
      " |      :param model: source model, used for extracting dataset information\n",
      " |      :param coefs: dictionary containing model coefficients\n",
      " |      :param threshold: (optional, only for binomial) decision threshold used for classification\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  Lambda\n",
      " |      DEPRECATED. Use ``self.lambda_`` instead\n",
      " |  \n",
      " |  alpha\n",
      " |      Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha\n",
      " |      represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the\n",
      " |      amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  beta_constraints\n",
      " |      Beta constraints\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  beta_epsilon\n",
      " |      Converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.0001``).\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  compute_p_values\n",
      " |      Request p-values computation, p-values work only with IRLSM solver and no regularization\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  custom_metric_func\n",
      " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  early_stopping\n",
      " |      Stop early when there is no more relative improvement on train or validation (if provided)\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  family\n",
      " |      Family. Use binomial for classification with logistic regression, others are for regression problems.\n",
      " |      \n",
      " |      One of: ``\"gaussian\"``, ``\"binomial\"``, ``\"quasibinomial\"``, ``\"ordinal\"``, ``\"multinomial\"``, ``\"poisson\"``,\n",
      " |      ``\"gamma\"``, ``\"tweedie\"``  (default: ``\"gaussian\"``).\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  gradient_epsilon\n",
      " |      Converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver. Default\n",
      " |      indicates: If lambda_search is set to False and lambda is equal to zero, the default value of gradient_epsilon\n",
      " |      is equal to .000001, otherwise the default value is .0001. If lambda_search is set to True, the conditional\n",
      " |      values above are 1E-8 and 1E-6 respectively.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  interaction_pairs\n",
      " |      A list of pairwise (first order) column interactions.\n",
      " |      \n",
      " |      Type: ``List[tuple]``.\n",
      " |  \n",
      " |  interactions\n",
      " |      A list of predictor column indices to interact. All pairwise combinations will be computed for the list.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  intercept\n",
      " |      Include constant term in the model\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  lambda_\n",
      " |      Regularization strength\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  lambda_min_ratio\n",
      " |      Minimum lambda used in lambda search, specified as a ratio of lambda_max (the smallest lambda that drives all\n",
      " |      coefficients to zero). Default indicates: if the number of observations is greater than the number of variables,\n",
      " |      then lambda_min_ratio is set to 0.0001; if the number of observations is less than the number of variables, then\n",
      " |      lambda_min_ratio is set to 0.01.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  lambda_search\n",
      " |      Use lambda search starting at lambda max, given lambda is then interpreted as lambda min\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  link\n",
      " |      One of: ``\"family_default\"``, ``\"identity\"``, ``\"logit\"``, ``\"log\"``, ``\"inverse\"``, ``\"tweedie\"``,\n",
      " |      ``\"ologit\"``, ``\"oprobit\"``, ``\"ologlog\"``  (default: ``\"family_default\"``).\n",
      " |  \n",
      " |  max_active_predictors\n",
      " |      Maximum number of active predictors during computation. Use as a stopping criterion to prevent expensive model\n",
      " |      building with many predictors. Default indicates: If the IRLSM solver is used, the value of\n",
      " |      max_active_predictors is set to 5000 otherwise it is set to 100000000.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Maximum number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_iterations\n",
      " |      Maximum number of iterations\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  missing_values_handling\n",
      " |      Handling of missing values. Either MeanImputation or Skip.\n",
      " |      \n",
      " |      One of: ``\"mean_imputation\"``, ``\"skip\"``  (default: ``\"mean_imputation\"``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  nlambdas\n",
      " |      Number of lambdas to be used in a search. Default indicates: If alpha is zero, with lambda search set to True,\n",
      " |      the value of nlamdas is set to 30 (fewer lambdas are needed for ridge regression) otherwise it is set to 100.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  non_negative\n",
      " |      Restrict coefficients (not intercept) to be non-negative\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  obj_reg\n",
      " |      Likelihood divider in objective value computation, default is 1/nobs\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  objective_epsilon\n",
      " |      Converge if  objective value changes less than this. Default indicates: If lambda_search is set to True the\n",
      " |      value of objective_epsilon is set to .0001. If the lambda_search is set to False and lambda is equal to zero,\n",
      " |      the value of objective_epsilon is set to .000001, for any other value of lambda the default value of\n",
      " |      objective_epsilon is set to .0001.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  prior\n",
      " |      Prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean\n",
      " |      of response does not reflect reality.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  remove_collinear_columns\n",
      " |      In case of linearly dependent columns, remove some of the dependent columns\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  solver\n",
      " |      AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small\n",
      " |      number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many columns.\n",
      " |      Coordinate descent is experimental (beta).\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"irlsm\"``, ``\"l_bfgs\"``, ``\"coordinate_descent_naive\"``, ``\"coordinate_descent\"``\n",
      " |      (default: ``\"auto\"``).\n",
      " |  \n",
      " |  standardize\n",
      " |      Standardize numeric columns to have zero mean and unit variance\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  tweedie_link_power\n",
      " |      Tweedie link power\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  tweedie_variance_power\n",
      " |      Tweedie variance power\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
      " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
      " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'glm'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  fit(self, x, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame x: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  levelone_frame_id(self)\n",
      " |      Fetch the levelone_frame_id for the model, if any.  Currently only used by H2OStackedEnsembleEstimator.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  metalearner(self)\n",
      " |      Print the metalearner for the model, if any.  Currently only used by H2OStackedEnsembleEstimator.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, plot=True, plot_stddev=True, figsize=(7, 10), server=False)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |      into cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data)\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Help on function import_file in module h2o.h2o:\n",
      "\n",
      "import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None, na_strings=None, pattern=None)\n",
      "    Import a dataset that is already on the cluster.\n",
      "    \n",
      "    The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n",
      "    cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n",
      "    multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n",
      "    the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n",
      "    If you running H2O server on your own maching, then both methods behave the same.\n",
      "    \n",
      "    :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n",
      "    :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n",
      "        automatically generated.\n",
      "    :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n",
      "    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "    :param sep: The field separator character. Values on each line of the file are separated by\n",
      "        this character. If not provided, the parser will automatically detect the separator.\n",
      "    :param col_names: A list of column names for the file.\n",
      "    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "        one will be guessed. The possible types a column may have are:\n",
      "    \n",
      "        - \"unknown\" - this will force the column to be parsed as all NA\n",
      "        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "        - \"string\"  - force the column to be parsed as a string\n",
      "        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "          data in the optimal manner.\n",
      "        - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "          Times can also contain \"AM\" or \"PM\".\n",
      "    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "        of column names to strings which are to be interpreted as missing values.\n",
      "    :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n",
      "        directory.\n",
      "    \n",
      "    :returns: a new :class:`H2OFrame` instance.\n",
      "    \n",
      "    :examples:\n",
      "        >>> # Single file import\n",
      "        >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n",
      "        >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n",
      "        >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n",
      "        ...                                pattern = \"iris_.*\\.csv\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "help(H2OGeneralizedLinearEstimator)\n",
    "help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "covtype_df = h2o.import_file(os.path.realpath(\"../DATA/covtype.full.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Elevation</th><th style=\"text-align: right;\">  Aspect</th><th style=\"text-align: right;\">  Slope</th><th style=\"text-align: right;\">  Horizontal_Distance_To_Hydrology</th><th style=\"text-align: right;\">  Vertical_Distance_To_Hydrology</th><th style=\"text-align: right;\">  Horizontal_Distance_To_Roadways</th><th style=\"text-align: right;\">  Hillshade_9am</th><th style=\"text-align: right;\">  Hillshade_Noon</th><th style=\"text-align: right;\">  Hillshade_3pm</th><th style=\"text-align: right;\">  Horizontal_Distance_To_Fire_Points</th><th>Wilderness_Area  </th><th>Soil_Type  </th><th>Cover_Type  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">       3066</td><td style=\"text-align: right;\">     124</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                                 0</td><td style=\"text-align: right;\">                               0</td><td style=\"text-align: right;\">                             1533</td><td style=\"text-align: right;\">            229</td><td style=\"text-align: right;\">             236</td><td style=\"text-align: right;\">            141</td><td style=\"text-align: right;\">                                 459</td><td>area_0           </td><td>type_22    </td><td>class_1     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3136</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">                               450</td><td style=\"text-align: right;\">                             -38</td><td style=\"text-align: right;\">                             1290</td><td style=\"text-align: right;\">            211</td><td style=\"text-align: right;\">             193</td><td style=\"text-align: right;\">            111</td><td style=\"text-align: right;\">                                1112</td><td>area_0           </td><td>type_28    </td><td>class_1     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       2655</td><td style=\"text-align: right;\">      28</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">                                42</td><td style=\"text-align: right;\">                               8</td><td style=\"text-align: right;\">                             1890</td><td style=\"text-align: right;\">            214</td><td style=\"text-align: right;\">             209</td><td style=\"text-align: right;\">            128</td><td style=\"text-align: right;\">                                1001</td><td>area_2           </td><td>type_9     </td><td>class_2     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3191</td><td style=\"text-align: right;\">      45</td><td style=\"text-align: right;\">     19</td><td style=\"text-align: right;\">                               323</td><td style=\"text-align: right;\">                              88</td><td style=\"text-align: right;\">                             3932</td><td style=\"text-align: right;\">            221</td><td style=\"text-align: right;\">             195</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">                                2919</td><td>area_0           </td><td>type_39    </td><td>class_2     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3217</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">                                30</td><td style=\"text-align: right;\">                               1</td><td style=\"text-align: right;\">                             3901</td><td style=\"text-align: right;\">            237</td><td style=\"text-align: right;\">             217</td><td style=\"text-align: right;\">            109</td><td style=\"text-align: right;\">                                2859</td><td>area_0           </td><td>type_22    </td><td>class_7     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3119</td><td style=\"text-align: right;\">     293</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">                                30</td><td style=\"text-align: right;\">                              10</td><td style=\"text-align: right;\">                             4810</td><td style=\"text-align: right;\">            182</td><td style=\"text-align: right;\">             237</td><td style=\"text-align: right;\">            194</td><td style=\"text-align: right;\">                                1200</td><td>area_0           </td><td>type_21    </td><td>class_1     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       2679</td><td style=\"text-align: right;\">      48</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">                               150</td><td style=\"text-align: right;\">                              24</td><td style=\"text-align: right;\">                             1588</td><td style=\"text-align: right;\">            223</td><td style=\"text-align: right;\">             224</td><td style=\"text-align: right;\">            136</td><td style=\"text-align: right;\">                                6265</td><td>area_0           </td><td>type_11    </td><td>class_2     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3261</td><td style=\"text-align: right;\">     322</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">                                30</td><td style=\"text-align: right;\">                               5</td><td style=\"text-align: right;\">                             5701</td><td style=\"text-align: right;\">            186</td><td style=\"text-align: right;\">             226</td><td style=\"text-align: right;\">            180</td><td style=\"text-align: right;\">                                 769</td><td>area_0           </td><td>type_21    </td><td>class_1     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       2885</td><td style=\"text-align: right;\">      26</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">                               192</td><td style=\"text-align: right;\">                              38</td><td style=\"text-align: right;\">                             3271</td><td style=\"text-align: right;\">            216</td><td style=\"text-align: right;\">             220</td><td style=\"text-align: right;\">            140</td><td style=\"text-align: right;\">                                2643</td><td>area_0           </td><td>type_28    </td><td>class_2     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3167</td><td style=\"text-align: right;\">     271</td><td style=\"text-align: right;\">     29</td><td style=\"text-align: right;\">                               242</td><td style=\"text-align: right;\">                              37</td><td style=\"text-align: right;\">                             4700</td><td style=\"text-align: right;\">            133</td><td style=\"text-align: right;\">             235</td><td style=\"text-align: right;\">            234</td><td style=\"text-align: right;\">                                3260</td><td>area_0           </td><td>type_28    </td><td>class_1     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Elevation        </th><th>Aspect            </th><th>Slope             </th><th>Horizontal_Distance_To_Hydrology  </th><th>Vertical_Distance_To_Hydrology  </th><th>Horizontal_Distance_To_Roadways  </th><th>Hillshade_9am     </th><th>Hillshade_Noon    </th><th>Hillshade_3pm     </th><th>Horizontal_Distance_To_Fire_Points  </th><th>Wilderness_Area  </th><th>Soil_Type  </th><th>Cover_Type  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>int               </td><td>int               </td><td>int                               </td><td>int                             </td><td>int                              </td><td>int               </td><td>int               </td><td>int               </td><td>int                                 </td><td>enum             </td><td>enum       </td><td>enum        </td></tr>\n",
       "<tr><td>mins   </td><td>1859.0           </td><td>0.0               </td><td>0.0               </td><td>0.0                               </td><td>-173.0                          </td><td>0.0                              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0                                 </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>mean   </td><td>2959.365300544568</td><td>155.65680743254856</td><td>14.103703537964787</td><td>269.4282166289166                 </td><td>46.41885537648099               </td><td>2350.14661142971                 </td><td>212.14604861861739</td><td>223.31871630878535</td><td>142.5282627553303 </td><td>1980.2912263430007                  </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>maxs   </td><td>3858.0           </td><td>360.0             </td><td>66.0              </td><td>1397.0                            </td><td>601.0                           </td><td>7117.0                           </td><td>254.0             </td><td>254.0             </td><td>254.0             </td><td>7173.0                              </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>sigma  </td><td>279.9847342506385</td><td>111.91372100329549</td><td>7.488241814480136 </td><td>212.54935559508115                </td><td>58.295231626887215              </td><td>1559.2548698976093               </td><td>26.769888805282132</td><td>19.76869715366642 </td><td>38.274529231410625</td><td>1324.1952097801095                  </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>4914              </td><td>656               </td><td>24603                             </td><td>38665                           </td><td>124                              </td><td>13                </td><td>5                 </td><td>1338              </td><td>51                                  </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>missing</td><td>0                </td><td>0                 </td><td>0                 </td><td>0                                 </td><td>0                               </td><td>0                                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                                   </td><td>0                </td><td>0          </td><td>0           </td></tr>\n",
       "<tr><td>0      </td><td>3066.0           </td><td>124.0             </td><td>5.0               </td><td>0.0                               </td><td>0.0                             </td><td>1533.0                           </td><td>229.0             </td><td>236.0             </td><td>141.0             </td><td>459.0                               </td><td>area_0           </td><td>type_22    </td><td>class_1     </td></tr>\n",
       "<tr><td>1      </td><td>3136.0           </td><td>32.0              </td><td>20.0              </td><td>450.0                             </td><td>-38.0                           </td><td>1290.0                           </td><td>211.0             </td><td>193.0             </td><td>111.0             </td><td>1112.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td></tr>\n",
       "<tr><td>2      </td><td>2655.0           </td><td>28.0              </td><td>14.0              </td><td>42.0                              </td><td>8.0                             </td><td>1890.0                           </td><td>214.0             </td><td>209.0             </td><td>128.0             </td><td>1001.0                              </td><td>area_2           </td><td>type_9     </td><td>class_2     </td></tr>\n",
       "<tr><td>3      </td><td>3191.0           </td><td>45.0              </td><td>19.0              </td><td>323.0                             </td><td>88.0                            </td><td>3932.0                           </td><td>221.0             </td><td>195.0             </td><td>100.0             </td><td>2919.0                              </td><td>area_0           </td><td>type_39    </td><td>class_2     </td></tr>\n",
       "<tr><td>4      </td><td>3217.0           </td><td>80.0              </td><td>13.0              </td><td>30.0                              </td><td>1.0                             </td><td>3901.0                           </td><td>237.0             </td><td>217.0             </td><td>109.0             </td><td>2859.0                              </td><td>area_0           </td><td>type_22    </td><td>class_7     </td></tr>\n",
       "<tr><td>5      </td><td>3119.0           </td><td>293.0             </td><td>13.0              </td><td>30.0                              </td><td>10.0                            </td><td>4810.0                           </td><td>182.0             </td><td>237.0             </td><td>194.0             </td><td>1200.0                              </td><td>area_0           </td><td>type_21    </td><td>class_1     </td></tr>\n",
       "<tr><td>6      </td><td>2679.0           </td><td>48.0              </td><td>7.0               </td><td>150.0                             </td><td>24.0                            </td><td>1588.0                           </td><td>223.0             </td><td>224.0             </td><td>136.0             </td><td>6265.0                              </td><td>area_0           </td><td>type_11    </td><td>class_2     </td></tr>\n",
       "<tr><td>7      </td><td>3261.0           </td><td>322.0             </td><td>13.0              </td><td>30.0                              </td><td>5.0                             </td><td>5701.0                           </td><td>186.0             </td><td>226.0             </td><td>180.0             </td><td>769.0                               </td><td>area_0           </td><td>type_21    </td><td>class_1     </td></tr>\n",
       "<tr><td>8      </td><td>2885.0           </td><td>26.0              </td><td>9.0               </td><td>192.0                             </td><td>38.0                            </td><td>3271.0                           </td><td>216.0             </td><td>220.0             </td><td>140.0             </td><td>2643.0                              </td><td>area_0           </td><td>type_28    </td><td>class_2     </td></tr>\n",
       "<tr><td>9      </td><td>3167.0           </td><td>271.0             </td><td>29.0              </td><td>242.0                             </td><td>37.0                            </td><td>4700.0                           </td><td>133.0             </td><td>235.0             </td><td>234.0             </td><td>3260.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #split the data as described above\n",
    "train, valid, test = covtype_df.split_frame([0.7, 0.15], seed=1234)\n",
    "\n",
    "#Prepare predictors and response columns\n",
    "covtype_X = covtype_df.col_names[:-1]     #last column is Cover_Type, our desired response variable \\n\",\n",
    "covtype_y = covtype_df.col_names[-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_multi_v1 = H2OGeneralizedLinearEstimator(\n",
    "    model_id='glm_v1',            #allows us to easily locate this model in Flow\n",
    "    family='multinomial',\n",
    "    solver='L_BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_multi_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view information about the model in [Flow](http://localhost:54321/) or within Python. \n",
    "To find more information in Flow, enter `getModel \"rf_covType_v1\"` into a cell and run in place pressing Ctrl-Enter. \n",
    "\n",
    "\n",
    "\n",
    "In Python, we can use call the model itself to get an overview of its stats,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  glm_v1\n",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.20948485767867384\n",
      "RMSE: 0.457695158024065\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.2101143165863004\n",
      "RMSE: 0.45838228214700927\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:48:51</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>490244.3713397</td>\n",
       "<td>1.2048958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:48:51</td>\n",
       "<td> 0.254 sec</td>\n",
       "<td>1</td>\n",
       "<td>390188.1819345</td>\n",
       "<td>0.9591928</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:48:51</td>\n",
       "<td> 0.374 sec</td>\n",
       "<td>2</td>\n",
       "<td>364701.2026063</td>\n",
       "<td>0.8967724</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:48:51</td>\n",
       "<td> 0.627 sec</td>\n",
       "<td>3</td>\n",
       "<td>340249.4056551</td>\n",
       "<td>0.8372369</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:48:52</td>\n",
       "<td> 0.880 sec</td>\n",
       "<td>4</td>\n",
       "<td>323802.2278831</td>\n",
       "<td>0.7975038</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:01</td>\n",
       "<td>10.699 sec</td>\n",
       "<td>45</td>\n",
       "<td>260029.3463549</td>\n",
       "<td>0.6535750</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:02</td>\n",
       "<td>10.938 sec</td>\n",
       "<td>46</td>\n",
       "<td>260032.0054209</td>\n",
       "<td>0.6534826</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:02</td>\n",
       "<td>11.177 sec</td>\n",
       "<td>47</td>\n",
       "<td>259914.4187691</td>\n",
       "<td>0.6533524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:02</td>\n",
       "<td>11.305 sec</td>\n",
       "<td>48</td>\n",
       "<td>259769.2058141</td>\n",
       "<td>0.6532509</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:02</td>\n",
       "<td>11.546 sec</td>\n",
       "<td>49</td>\n",
       "<td>259741.9126070</td>\n",
       "<td>0.6532148</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "---  -------------------  ----------  ------------  -------------------------  ------------------\n",
       "     2018-03-14 16:48:51  0.000 sec   0             490244.3713396542          1.2048957580292183\n",
       "     2018-03-14 16:48:51  0.254 sec   1             390188.1819345459          0.9591928195326627\n",
       "     2018-03-14 16:48:51  0.374 sec   2             364701.202606348           0.8967723729000835\n",
       "     2018-03-14 16:48:51  0.627 sec   3             340249.40565508784         0.8372369493492284\n",
       "     2018-03-14 16:48:52  0.880 sec   4             323802.22788305173         0.7975037904084802\n",
       "---  ---                  ---         ---           ---                        ---\n",
       "     2018-03-14 16:49:01  10.699 sec  45            260029.3463548987          0.6535750068479454\n",
       "     2018-03-14 16:49:02  10.938 sec  46            260032.0054208953          0.6534826038517352\n",
       "     2018-03-14 16:49:02  11.177 sec  47            259914.41876910708         0.6533523872781914\n",
       "     2018-03-14 16:49:02  11.305 sec  48            259769.205814127           0.6532508632072033\n",
       "     2018-03-14 16:49:02  11.546 sec  49            259741.91260696214         0.6532148188204394"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out a little more about its performance, we can look at its hit ratio table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7217729</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9671201</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9934171</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9982538</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9997013</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999886</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.721773\n",
       "2    0.96712\n",
       "3    0.993417\n",
       "4    0.998254\n",
       "5    0.999701\n",
       "6    0.999989\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v1.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_multi_v2 = H2OGeneralizedLinearEstimator(\n",
    "    model_id='glm_v2',  \n",
    "    family='multinomial',\n",
    "    solver='L_BFGS',\n",
    "    Lambda=0.0001                 #default value 0.001\n",
    "    )\n",
    "glm_multi_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  glm_v2\n",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.20779920667152163\n",
      "RMSE: 0.45584998263850096\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.20842800000336265\n",
      "RMSE: 0.45653915495098846\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:16</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>490244.3713397</td>\n",
       "<td>1.2048958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:16</td>\n",
       "<td> 0.236 sec</td>\n",
       "<td>1</td>\n",
       "<td>390179.3904457</td>\n",
       "<td>0.9590567</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:16</td>\n",
       "<td> 0.349 sec</td>\n",
       "<td>2</td>\n",
       "<td>364681.3958329</td>\n",
       "<td>0.8964892</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:16</td>\n",
       "<td> 0.594 sec</td>\n",
       "<td>3</td>\n",
       "<td>340243.6026901</td>\n",
       "<td>0.8366837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:17</td>\n",
       "<td> 0.828 sec</td>\n",
       "<td>4</td>\n",
       "<td>323818.0586213</td>\n",
       "<td>0.7966307</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:27</td>\n",
       "<td>11.635 sec</td>\n",
       "<td>48</td>\n",
       "<td>258871.3363242</td>\n",
       "<td>0.6445755</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:28</td>\n",
       "<td>11.867 sec</td>\n",
       "<td>49</td>\n",
       "<td>258771.3770813</td>\n",
       "<td>0.6444419</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:28</td>\n",
       "<td>12.160 sec</td>\n",
       "<td>50</td>\n",
       "<td>258715.5687938</td>\n",
       "<td>0.6443253</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:28</td>\n",
       "<td>12.420 sec</td>\n",
       "<td>51</td>\n",
       "<td>258653.5459975</td>\n",
       "<td>0.6442457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:49:28</td>\n",
       "<td>12.743 sec</td>\n",
       "<td>52</td>\n",
       "<td>258612.7131867</td>\n",
       "<td>0.6441874</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "---  -------------------  ----------  ------------  -------------------------  ------------------\n",
       "     2018-03-14 16:49:16  0.000 sec   0             490244.3713396542          1.2048957580292183\n",
       "     2018-03-14 16:49:16  0.236 sec   1             390179.39044565544         0.9590567324641854\n",
       "     2018-03-14 16:49:16  0.349 sec   2             364681.3958328747          0.8964892094828179\n",
       "     2018-03-14 16:49:16  0.594 sec   3             340243.60269009974         0.836683705380802\n",
       "     2018-03-14 16:49:17  0.828 sec   4             323818.0586212904          0.7966306994701585\n",
       "---  ---                  ---         ---           ---                        ---\n",
       "     2018-03-14 16:49:27  11.635 sec  48            258871.3363242393          0.6445755069096427\n",
       "     2018-03-14 16:49:28  11.867 sec  49            258771.37708128226         0.644441875157338\n",
       "     2018-03-14 16:49:28  12.160 sec  50            258715.56879378454         0.6443252812981544\n",
       "     2018-03-14 16:49:28  12.420 sec  51            258653.54599745033         0.6442457493816538\n",
       "     2018-03-14 16:49:28  12.743 sec  52            258612.71318665033         0.6441874021786154"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7220027</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9670627</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9936354</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9983112</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9997588</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999655</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.722003\n",
       "2    0.967063\n",
       "3    0.993635\n",
       "4    0.998311\n",
       "5    0.999759\n",
       "6    0.999966\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a noticeable improvement in the MSE, and our hit ratio has improved from coin-flip to 72%. \n",
    "\n",
    "Let's look at the confusion matrix to see if we can gather any more insight on the errors in our multinomial classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>class_1</b></td>\n",
       "<td><b>class_2</b></td>\n",
       "<td><b>class_3</b></td>\n",
       "<td><b>class_4</b></td>\n",
       "<td><b>class_5</b></td>\n",
       "<td><b>class_6</b></td>\n",
       "<td><b>class_7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>22107.0</td>\n",
       "<td>8964.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>604.0</td>\n",
       "<td>0.3023322</td>\n",
       "<td>9,580 / 31,687</td></tr>\n",
       "<tr><td>7691.0</td>\n",
       "<td>33942.0</td>\n",
       "<td>529.0</td>\n",
       "<td>2.0</td>\n",
       "<td>33.0</td>\n",
       "<td>236.0</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2004805</td>\n",
       "<td>8,511 / 42,453</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>532.0</td>\n",
       "<td>4326.0</td>\n",
       "<td>63.0</td>\n",
       "<td>4.0</td>\n",
       "<td>388.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1857708</td>\n",
       "<td>987 / 5,313</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>240.0</td>\n",
       "<td>125.0</td>\n",
       "<td>0.0</td>\n",
       "<td>66.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7106481</td>\n",
       "<td>307 / 432</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>1396.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9965493</td>\n",
       "<td>1,444 / 1,449</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>643.0</td>\n",
       "<td>1296.0</td>\n",
       "<td>3.0</td>\n",
       "<td>5.0</td>\n",
       "<td>651.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7494226</td>\n",
       "<td>1,947 / 2,598</td></tr>\n",
       "<tr><td>1392.0</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.4569409</td>\n",
       "<td>1,422 / 3,112</td></tr>\n",
       "<tr><td>31194.0</td>\n",
       "<td>45508.0</td>\n",
       "<td>6428.0</td>\n",
       "<td>193.0</td>\n",
       "<td>47.0</td>\n",
       "<td>1360.0</td>\n",
       "<td>2314.0</td>\n",
       "<td>0.2779973</td>\n",
       "<td>24,198 / 87,044</td></tr></table></div>"
      ],
      "text/plain": [
       "class_1    class_2    class_3    class_4    class_5    class_6    class_7    Error     Rate\n",
       "---------  ---------  ---------  ---------  ---------  ---------  ---------  --------  ---------------\n",
       "22107      8964       2          0          0          10         604        0.302332  9,580 / 31,687\n",
       "7691       33942      529        2          33         236        20         0.200481  8,511 / 42,453\n",
       "0          532        4326       63         4          388        0          0.185771  987 / 5,313\n",
       "0          1          240        125        0          66         0          0.710648  307 / 432\n",
       "4          1396       35         0          5          9          0          0.996549  1,444 / 1,449\n",
       "0          643        1296       3          5          651        0          0.749423  1,947 / 2,598\n",
       "1392       30         0          0          0          0          1690       0.456941  1,422 / 3,112\n",
       "31194      45508      6428       193        47         1360       2314       0.277997  24,198 / 87,044"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v2.confusion_matrix(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above confusion matrix, our model is struggling to correctly distinguish between covertype classes 1 and 2. To learn more about this, let's shrink the scope of our problem to a binomial classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = covtype_df[covtype_df['Cover_Type'] == 'class_1']\n",
    "c2 = covtype_df[covtype_df['Cover_Type'] == 'class_2']\n",
    "df_b = c1.rbind(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Elevation        </th><th>Aspect            </th><th>Slope             </th><th>Horizontal_Distance_To_Hydrology  </th><th>Vertical_Distance_To_Hydrology  </th><th>Horizontal_Distance_To_Roadways  </th><th>Hillshade_9am     </th><th>Hillshade_Noon    </th><th>Hillshade_3pm     </th><th>Horizontal_Distance_To_Fire_Points  </th><th>Wilderness_Area  </th><th>Soil_Type  </th><th>Cover_Type  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>int               </td><td>int               </td><td>int                               </td><td>int                             </td><td>int                              </td><td>int               </td><td>int               </td><td>int               </td><td>int                                 </td><td>enum             </td><td>enum       </td><td>enum        </td></tr>\n",
       "<tr><td>mins   </td><td>2147.0           </td><td>0.0               </td><td>0.0               </td><td>0.0                               </td><td>-166.0                          </td><td>0.0                              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0                                 </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>mean   </td><td>3010.200258659015</td><td>152.64896469035017</td><td>13.335219388648646</td><td>276.8974659499657                 </td><td>44.4413908310768                </td><td>2511.6484123455793               </td><td>213.18706974363116</td><td>224.5172237265759 </td><td>143.23633620283184</td><td>2103.0536852173664                  </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>maxs   </td><td>3686.0           </td><td>360.0             </td><td>63.0              </td><td>1368.0                            </td><td>595.0                           </td><td>7078.0                           </td><td>254.0             </td><td>254.0             </td><td>253.0             </td><td>7150.0                              </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>sigma  </td><td>202.9089483173579</td><td>111.3236125255111 </td><td>6.986221645549852 </td><td>212.71416776089166                </td><td>57.00085845225439               </td><td>1570.7547099886986               </td><td>24.727003380921136</td><td>18.405880450701385</td><td>35.962843924715436</td><td>1344.928654620616                   </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>672               </td><td>102               </td><td>2938                              </td><td>4861                            </td><td>11                               </td><td>2                 </td><td>1                 </td><td>111               </td><td>5                                   </td><td>                 </td><td>           </td><td>            </td></tr>\n",
       "<tr><td>missing</td><td>0                </td><td>0                 </td><td>0                 </td><td>0                                 </td><td>0                               </td><td>0                                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                                   </td><td>0                </td><td>0          </td><td>0           </td></tr>\n",
       "<tr><td>0      </td><td>3066.0           </td><td>124.0             </td><td>5.0               </td><td>0.0                               </td><td>0.0                             </td><td>1533.0                           </td><td>229.0             </td><td>236.0             </td><td>141.0             </td><td>459.0                               </td><td>area_0           </td><td>type_22    </td><td>class_1     </td></tr>\n",
       "<tr><td>1      </td><td>2972.0           </td><td>100.0             </td><td>4.0               </td><td>175.0                             </td><td>13.0                            </td><td>5031.0                           </td><td>227.0             </td><td>234.0             </td><td>142.0             </td><td>6198.0                              </td><td>area_0           </td><td>type_19    </td><td>class_1     </td></tr>\n",
       "<tr><td>2      </td><td>3301.0           </td><td>205.0             </td><td>4.0               </td><td>190.0                             </td><td>-1.0                            </td><td>5750.0                           </td><td>217.0             </td><td>243.0             </td><td>162.0             </td><td>573.0                               </td><td>area_0           </td><td>type_37    </td><td>class_1     </td></tr>\n",
       "<tr><td>3      </td><td>3465.0           </td><td>258.0             </td><td>9.0               </td><td>677.0                             </td><td>109.0                           </td><td>2644.0                           </td><td>198.0             </td><td>246.0             </td><td>186.0             </td><td>1438.0                              </td><td>area_2           </td><td>type_37    </td><td>class_1     </td></tr>\n",
       "<tr><td>4      </td><td>3038.0           </td><td>302.0             </td><td>9.0               </td><td>134.0                             </td><td>15.0                            </td><td>2061.0                           </td><td>196.0             </td><td>236.0             </td><td>180.0             </td><td>1260.0                              </td><td>area_2           </td><td>type_21    </td><td>class_1     </td></tr>\n",
       "<tr><td>5      </td><td>2843.0           </td><td>119.0             </td><td>15.0              </td><td>85.0                              </td><td>14.0                            </td><td>1181.0                           </td><td>245.0             </td><td>225.0             </td><td>104.0             </td><td>782.0                               </td><td>area_2           </td><td>type_31    </td><td>class_1     </td></tr>\n",
       "<tr><td>6      </td><td>2955.0           </td><td>221.0             </td><td>14.0              </td><td>201.0                             </td><td>29.0                            </td><td>5370.0                           </td><td>202.0             </td><td>253.0             </td><td>184.0             </td><td>3206.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td></tr>\n",
       "<tr><td>7      </td><td>3168.0           </td><td>351.0             </td><td>12.0              </td><td>812.0                             </td><td>-6.0                            </td><td>4170.0                           </td><td>198.0             </td><td>219.0             </td><td>159.0             </td><td>3915.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td></tr>\n",
       "<tr><td>8      </td><td>3138.0           </td><td>71.0              </td><td>16.0              </td><td>42.0                              </td><td>7.0                             </td><td>2630.0                           </td><td>236.0             </td><td>206.0             </td><td>96.0              </td><td>1358.0                              </td><td>area_2           </td><td>type_22    </td><td>class_1     </td></tr>\n",
       "<tr><td>9      </td><td>3166.0           </td><td>54.0              </td><td>7.0               </td><td>30.0                              </td><td>-1.0                            </td><td>3121.0                           </td><td>224.0             </td><td>225.0             </td><td>136.0             </td><td>3416.0                              </td><td>area_0           </td><td>type_22    </td><td>class_1     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data\n",
    "train_b, valid_b, test_b = df_b.split_frame([0.7, 0.15], seed=1234)\n",
    "#train_b.summary()\n",
    "valid_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: | (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000134d4ffffffff$_ba44fa5e3efce7edb5d7ba38ef664e0f failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-234641a61835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L_BFGS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     family='binomial')\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mglm_binom_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovtype_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovtype_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_model_scoring_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, verbose_model_scoring_history)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 77\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000134d4ffffffff$_ba44fa5e3efce7edb5d7ba38ef664e0f failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_v1 = H2OGeneralizedLinearEstimator(\n",
    "    model_id='glm_v3',\n",
    "    solver='L_BFGS',\n",
    "    family='binomial')\n",
    "glm_binom_v1.train(covtype_X, covtype_y, training_frame=train_b, validation_frame=valid_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c2c2608f1040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglm_binom_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_v1.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_column(train_df, train, valid, test, col):\n",
    "    '''\n",
    "    Convenience function to change a column from numerical to categorical\n",
    "    We use train_df only for bucketing with histograms.\n",
    "    Uses np.histogram to generate a histogram, with the buckets forming the categories of our new categorical.\n",
    "    Picks buckets based on training data, then applies the same classification to the test and validation sets\n",
    "    \n",
    "    Assumes that train, valid, test will have the same histogram behavior.\n",
    "    '''\n",
    "    only_col= train_df[col]                            #Isolate the column in question from the training frame\n",
    "    counts, breaks = np.histogram(only_col, bins=20)   #Generate counts and breaks for our histogram\n",
    "    min_val = min(only_col)-1                          #Establish min and max values\n",
    "    max_val = max(only_col)+1\n",
    "    \n",
    "    new_b = [min_val]                                  #Redefine breaks such that each bucket has enough support\n",
    "    for i in range(19):\n",
    "        if counts[i] > 1000 and counts[i+1] > 1000:\n",
    "            new_b.append(breaks[i+1])\n",
    "    new_b.append(max_val)\n",
    "    names = [col + '_' + str(x) for x in range(len(new_b)-1)]  #Generate names for buckets, these will be categorical names\n",
    "    \n",
    "    train[col+\"_cut\"] = train[col].cut(breaks=new_b, labels=names)\n",
    "    valid[col+\"_cut\"] = valid[col].cut(breaks=new_b, labels=names)\n",
    "    test[col+\"_cut\"] = test[col].cut(breaks=new_b, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(train, valid, test):\n",
    "    '''\n",
    "    Helper function to add a specific set of features to our covertype dataset\n",
    "    '''\n",
    "    #pull train dataset into Python\n",
    "    train_df = train.as_data_frame(True)\n",
    "    \n",
    "    #Make categoricals for several columns\n",
    "    cut_column(train_df, train, valid, test, \"Elevation\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_Noon\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_9am\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_3pm\")\n",
    "    cut_column(train_df, train, valid, test, \"Horizontal_Distance_To_Hydrology\")\n",
    "    cut_column(train_df, train, valid, test, \"Slope\")\n",
    "    cut_column(train_df, train, valid, test, \"Horizontal_Distance_To_Roadways\")\n",
    "    cut_column(train_df, train, valid, test, \"Aspect\")\n",
    "\n",
    "\n",
    "    #Add interaction columns for a subset of columns\\n\",\n",
    "    interaction_cols1 = [\"Elevation_cut\",\n",
    "                         \"Wilderness_Area\",\n",
    "                         \"Soil_Type\",\n",
    "                          \"Hillshade_Noon_cut\",\n",
    "                           \"Hillshade_9am_cut\",\n",
    "                           \"Hillshade_3pm_cut\",\n",
    "                           \"Horizontal_Distance_To_Hydrology_cut\",\n",
    "                           \"Slope_cut\",\n",
    "                           \"Horizontal_Distance_To_Roadways_cut\",\n",
    "                           \"Aspect_cut\"]\n",
    "\n",
    "    train_cols = train.interaction(factors=interaction_cols1,    #Generate pairwise columns\n",
    "        pairwise=True,\n",
    "        max_factors=1000,\n",
    "        min_occurrence=100,\n",
    "        destination_frame=\"itrain\")\n",
    "    \n",
    "    valid_cols = valid.interaction(factors=interaction_cols1,\n",
    "        pairwise=True,\n",
    "        max_factors=1000,\n",
    "        min_occurrence=100,\n",
    "        destination_frame=\"ivalid\")\n",
    "    \n",
    "    test_cols = test.interaction(factors=interaction_cols1,\n",
    "        pairwise=True,\n",
    "        max_factors=1000,\n",
    "        min_occurrence=100,\n",
    "        destination_frame=\"itest\")\n",
    "\n",
    "    train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "    valid = valid.cbind(valid_cols)\n",
    "    test = test.cbind(test_cols)\n",
    "    \n",
    "                                \n",
    "    #Add a three-way interaction for Hillshade\n",
    "    interaction_cols2 = [\"Hillshade_Noon_cut\",\"Hillshade_9am_cut\",\"Hillshade_3pm_cut\"]\n",
    "    \n",
    "                         \n",
    "    train_cols = train.interaction(factors=interaction_cols2,    #Generate pairwise columns\n",
    "        pairwise=False,\n",
    "        max_factors=1000,\n",
    "        min_occurrence=100,\n",
    "        destination_frame=\"itrain\")\n",
    "    \n",
    "    valid_cols = valid.interaction(factors=interaction_cols2,\n",
    "        pairwise=False,\n",
    "        max_factors=1000,\n",
    "        min_occurrence=100,\n",
    "        destination_frame=\"ivalid\")\n",
    "    \n",
    "    test_cols = test.interaction(factors=interaction_cols2,\n",
    "        pairwise=False,\n",
    "        max_factors=1000,\n",
    "        min_occurrence=100,\n",
    "        destination_frame=\"itest\")\n",
    "    \n",
    "    train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "    valid = valid.cbind(valid_cols)\n",
    "    test = test.cbind(test_cols)\n",
    "\n",
    "                                 \n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_bf, valid_bf, test_bf = add_features(train_b, valid_b, test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Elevation         </th><th>Aspect            </th><th>Slope             </th><th>Horizontal_Distance_To_Hydrology  </th><th>Vertical_Distance_To_Hydrology  </th><th>Horizontal_Distance_To_Roadways  </th><th>Hillshade_9am     </th><th>Hillshade_Noon    </th><th>Hillshade_3pm     </th><th>Horizontal_Distance_To_Fire_Points  </th><th>Wilderness_Area  </th><th>Soil_Type  </th><th>Cover_Type  </th><th>Elevation_cut  </th><th>Hillshade_Noon_cut  </th><th>Hillshade_9am_cut  </th><th>Hillshade_3pm_cut  </th><th>Horizontal_Distance_To_Hydrology_cut  </th><th>Slope_cut  </th><th>Horizontal_Distance_To_Roadways_cut  </th><th>Aspect_cut  </th><th>Hillshade_Noon_cut_Hillshade_9am_cut_Hillshade_3pm_cut  </th><th>Hillshade_Noon_cut_Hillshade_9am_cut_Hillshade_3pm_cut0  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>int               </td><td>int               </td><td>int                               </td><td>int                             </td><td>int                              </td><td>int               </td><td>int               </td><td>int               </td><td>int                                 </td><td>enum             </td><td>enum       </td><td>enum        </td><td>enum           </td><td>enum                </td><td>enum               </td><td>enum               </td><td>enum                                  </td><td>enum       </td><td>enum                                 </td><td>enum        </td><td>enum                                                    </td><td>enum                                                     </td></tr>\n",
       "<tr><td>mins   </td><td>2142.0            </td><td>0.0               </td><td>0.0               </td><td>0.0                               </td><td>-166.0                          </td><td>0.0                              </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0                                 </td><td>                 </td><td>           </td><td>            </td><td>               </td><td>                    </td><td>                   </td><td>                   </td><td>                                      </td><td>           </td><td>                                     </td><td>            </td><td>                                                        </td><td>                                                         </td></tr>\n",
       "<tr><td>mean   </td><td>3009.8651868471597</td><td>154.02716623312205</td><td>13.373835629870173</td><td>275.57496380719465                </td><td>44.27077697733842               </td><td>2509.7929425471643               </td><td>213.03225052919356</td><td>224.5165016120939 </td><td>143.39138697751144</td><td>2100.479982927378                   </td><td>                 </td><td>           </td><td>            </td><td>               </td><td>                    </td><td>                   </td><td>                   </td><td>                                      </td><td>           </td><td>                                     </td><td>            </td><td>                                                        </td><td>                                                         </td></tr>\n",
       "<tr><td>maxs   </td><td>3680.0            </td><td>360.0             </td><td>66.0              </td><td>1397.0                            </td><td>601.0                           </td><td>7117.0                           </td><td>254.0             </td><td>254.0             </td><td>254.0             </td><td>7173.0                              </td><td>                 </td><td>           </td><td>            </td><td>               </td><td>                    </td><td>                   </td><td>                   </td><td>                                      </td><td>           </td><td>                                     </td><td>            </td><td>                                                        </td><td>                                                         </td></tr>\n",
       "<tr><td>sigma  </td><td>202.65600833565   </td><td>111.67382431290244</td><td>6.9866401755217105</td><td>213.15808640964318                </td><td>57.24285432412293               </td><td>1571.0628085443263               </td><td>24.918830103394665</td><td>18.387246591531216</td><td>36.17654203721041 </td><td>1349.7823750892069                  </td><td>                 </td><td>           </td><td>            </td><td>               </td><td>                    </td><td>                   </td><td>                   </td><td>                                      </td><td>           </td><td>                                     </td><td>            </td><td>                                                        </td><td>                                                         </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>3073              </td><td>419               </td><td>13743                             </td><td>22581                           </td><td>32                               </td><td>6                 </td><td>2                 </td><td>523               </td><td>29                                  </td><td>                 </td><td>           </td><td>            </td><td>               </td><td>                    </td><td>                   </td><td>                   </td><td>                                      </td><td>           </td><td>                                     </td><td>            </td><td>                                                        </td><td>                                                         </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                                 </td><td>0                               </td><td>0                                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                                   </td><td>0                </td><td>0          </td><td>0           </td><td>0              </td><td>0                   </td><td>0                  </td><td>0                  </td><td>0                                     </td><td>0          </td><td>0                                    </td><td>0           </td><td>0                                                       </td><td>0                                                        </td></tr>\n",
       "<tr><td>0      </td><td>3136.0            </td><td>32.0              </td><td>20.0              </td><td>450.0                             </td><td>-38.0                           </td><td>1290.0                           </td><td>211.0             </td><td>193.0             </td><td>111.0             </td><td>1112.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td><td>Elevation_8    </td><td>Hillshade_Noon_3    </td><td>Hillshade_9am_7    </td><td>Hillshade_3pm_5    </td><td>Horizontal_Distance_To_Hydrology_6    </td><td>Slope_6    </td><td>Horizontal_Distance_To_Roadways_3    </td><td>Aspect_1    </td><td>Hillshade_Noon_3_Hillshade_9am_7_Hillshade_3pm_5        </td><td>Hillshade_Noon_3_Hillshade_9am_7_Hillshade_3pm_5         </td></tr>\n",
       "<tr><td>1      </td><td>3119.0            </td><td>293.0             </td><td>13.0              </td><td>30.0                              </td><td>10.0                            </td><td>4810.0                           </td><td>182.0             </td><td>237.0             </td><td>194.0             </td><td>1200.0                              </td><td>area_0           </td><td>type_21    </td><td>class_1     </td><td>Elevation_8    </td><td>Hillshade_Noon_6    </td><td>Hillshade_9am_5    </td><td>Hillshade_3pm_12   </td><td>Horizontal_Distance_To_Hydrology_0    </td><td>Slope_3    </td><td>Horizontal_Distance_To_Roadways_13   </td><td>Aspect_16   </td><td>Hillshade_Noon_6_Hillshade_9am_5_Hillshade_3pm_12       </td><td>Hillshade_Noon_6_Hillshade_9am_5_Hillshade_3pm_12        </td></tr>\n",
       "<tr><td>2      </td><td>3167.0            </td><td>271.0             </td><td>29.0              </td><td>242.0                             </td><td>37.0                            </td><td>4700.0                           </td><td>133.0             </td><td>235.0             </td><td>234.0             </td><td>3260.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td><td>Elevation_9    </td><td>Hillshade_Noon_6    </td><td>Hillshade_9am_1    </td><td>Hillshade_3pm_15   </td><td>Horizontal_Distance_To_Hydrology_3    </td><td>Slope_8    </td><td>Horizontal_Distance_To_Roadways_13   </td><td>Aspect_15   </td><td>Hillshade_Noon_6_Hillshade_9am_1_Hillshade_3pm_15       </td><td>Hillshade_Noon_6_Hillshade_9am_1_Hillshade_3pm_15        </td></tr>\n",
       "<tr><td>3      </td><td>3227.0            </td><td>32.0              </td><td>6.0               </td><td>108.0                             </td><td>13.0                            </td><td>5542.0                           </td><td>219.0             </td><td>227.0             </td><td>145.0             </td><td>765.0                               </td><td>area_0           </td><td>type_21    </td><td>class_1     </td><td>Elevation_10   </td><td>Hillshade_Noon_5    </td><td>Hillshade_9am_8    </td><td>Hillshade_3pm_8    </td><td>Horizontal_Distance_To_Hydrology_1    </td><td>Slope_1    </td><td>Horizontal_Distance_To_Roadways_15   </td><td>Aspect_1    </td><td>Hillshade_Noon_5_Hillshade_9am_8_Hillshade_3pm_8        </td><td>Hillshade_Noon_5_Hillshade_9am_8_Hillshade_3pm_8         </td></tr>\n",
       "<tr><td>4      </td><td>2853.0            </td><td>124.0             </td><td>12.0              </td><td>30.0                              </td><td>-5.0                            </td><td>1485.0                           </td><td>240.0             </td><td>231.0             </td><td>119.0             </td><td>2497.0                              </td><td>area_2           </td><td>type_19    </td><td>class_1     </td><td>Elevation_5    </td><td>Hillshade_Noon_6    </td><td>Hillshade_9am_9    </td><td>Hillshade_3pm_6    </td><td>Horizontal_Distance_To_Hydrology_0    </td><td>Slope_3    </td><td>Horizontal_Distance_To_Roadways_4    </td><td>Aspect_6    </td><td>Hillshade_Noon_6_Hillshade_9am_9_Hillshade_3pm_6        </td><td>Hillshade_Noon_6_Hillshade_9am_9_Hillshade_3pm_6         </td></tr>\n",
       "<tr><td>5      </td><td>3301.0            </td><td>220.0             </td><td>33.0              </td><td>446.0                             </td><td>178.0                           </td><td>3182.0                           </td><td>164.0             </td><td>249.0             </td><td>203.0             </td><td>3013.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td><td>Elevation_11   </td><td>Hillshade_Noon_7    </td><td>Hillshade_9am_3    </td><td>Hillshade_3pm_12   </td><td>Horizontal_Distance_To_Hydrology_6    </td><td>Slope_9    </td><td>Horizontal_Distance_To_Roadways_8    </td><td>Aspect_12   </td><td>other                                                   </td><td>other                                                    </td></tr>\n",
       "<tr><td>6      </td><td>3238.0            </td><td>128.0             </td><td>12.0              </td><td>319.0                             </td><td>73.0                            </td><td>3879.0                           </td><td>239.0             </td><td>233.0             </td><td>122.0             </td><td>618.0                               </td><td>area_2           </td><td>type_32    </td><td>class_1     </td><td>Elevation_10   </td><td>Hillshade_Noon_6    </td><td>Hillshade_9am_9    </td><td>Hillshade_3pm_6    </td><td>Horizontal_Distance_To_Hydrology_4    </td><td>Slope_3    </td><td>Horizontal_Distance_To_Roadways_10   </td><td>Aspect_7    </td><td>Hillshade_Noon_6_Hillshade_9am_9_Hillshade_3pm_6        </td><td>Hillshade_Noon_6_Hillshade_9am_9_Hillshade_3pm_6         </td></tr>\n",
       "<tr><td>7      </td><td>3154.0            </td><td>313.0             </td><td>17.0              </td><td>67.0                              </td><td>15.0                            </td><td>2397.0                           </td><td>173.0             </td><td>225.0             </td><td>192.0             </td><td>1024.0                              </td><td>area_2           </td><td>type_22    </td><td>class_1     </td><td>Elevation_9    </td><td>Hillshade_Noon_5    </td><td>Hillshade_9am_4    </td><td>Hillshade_3pm_12   </td><td>Horizontal_Distance_To_Hydrology_0    </td><td>Slope_5    </td><td>Horizontal_Distance_To_Roadways_6    </td><td>Aspect_17   </td><td>Hillshade_Noon_5_Hillshade_9am_4_Hillshade_3pm_12       </td><td>Hillshade_Noon_5_Hillshade_9am_4_Hillshade_3pm_12        </td></tr>\n",
       "<tr><td>8      </td><td>3232.0            </td><td>149.0             </td><td>7.0               </td><td>95.0                              </td><td>6.0                             </td><td>3285.0                           </td><td>229.0             </td><td>240.0             </td><td>143.0             </td><td>2041.0                              </td><td>area_0           </td><td>type_28    </td><td>class_1     </td><td>Elevation_10   </td><td>Hillshade_Noon_6    </td><td>Hillshade_9am_9    </td><td>Hillshade_3pm_8    </td><td>Horizontal_Distance_To_Hydrology_1    </td><td>Slope_2    </td><td>Horizontal_Distance_To_Roadways_9    </td><td>Aspect_8    </td><td>Hillshade_Noon_6_Hillshade_9am_9_Hillshade_3pm_8        </td><td>Hillshade_Noon_6_Hillshade_9am_9_Hillshade_3pm_8         </td></tr>\n",
       "<tr><td>9      </td><td>3335.0            </td><td>305.0             </td><td>9.0               </td><td>256.0                             </td><td>37.0                            </td><td>1509.0                           </td><td>195.0             </td><td>235.0             </td><td>181.0             </td><td>1784.0                              </td><td>area_2           </td><td>type_31    </td><td>class_1     </td><td>Elevation_11   </td><td>Hillshade_Noon_6    </td><td>Hillshade_9am_6    </td><td>Hillshade_3pm_11   </td><td>Horizontal_Distance_To_Hydrology_3    </td><td>Slope_2    </td><td>Horizontal_Distance_To_Roadways_4    </td><td>Aspect_16   </td><td>Hillshade_Noon_6_Hillshade_9am_6_Hillshade_3pm_11       </td><td>Hillshade_Noon_6_Hillshade_9am_6_Hillshade_3pm_11        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: | (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000134d4ffffffff$_8b13abf778b5cfeea3a147fb69e9401a failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-749bd533ec23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mglm_binom_feat_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OGeneralizedLinearEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L_BFGS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glm_v4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglm_binom_feat_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovtype_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovtype_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_bf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_bf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_model_scoring_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, verbose_model_scoring_history)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 77\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000134d4ffffffff$_8b13abf778b5cfeea3a147fb69e9401a failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_feat_1 = H2OGeneralizedLinearEstimator(family='binomial', solver='L_BFGS', model_id='glm_v4')\n",
    "glm_binom_feat_1.train(covtype_X, covtype_y, training_frame=train_bf, validation_frame=valid_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b442de1c7e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglm_binom_feat_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_feat_1.accuracy(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: | (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000134d4ffffffff$_955bbdee8f60d4e4c08c0ea92e68497b failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-65876bdc093f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mglm_binom_feat_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OGeneralizedLinearEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L_BFGS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glm_v5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglm_binom_feat_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovtype_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovtype_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_bf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_bf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_model_scoring_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, verbose_model_scoring_history)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 77\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000134d4ffffffff$_955bbdee8f60d4e4c08c0ea92e68497b failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_feat_2 = H2OGeneralizedLinearEstimator(family='binomial', solver='L_BFGS', model_id='glm_v5', Lambda=0.001)\n",
    "glm_binom_feat_2.train(covtype_X, covtype_y, training_frame=train_bf, validation_frame=valid_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a4a2db78d6ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglm_binom_feat_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_feat_2.accuracy(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: | (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000134d4ffffffff$_a5d87b9a9506886dd041ae10527c40ef failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7883948c9e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mglm_binom_feat_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OGeneralizedLinearEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glm_v6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglm_binom_feat_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovtype_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovtype_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_bf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_bf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_model_scoring_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, verbose_model_scoring_history)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 77\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000134d4ffffffff$_a5d87b9a9506886dd041ae10527c40ef failed with an exception: java.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\nstacktrace: \njava.lang.AssertionError: x out of bounds, expected <0,1> range, got NaN\n\tat hex.glm.GLMModel$GLMWeightsFun.link(GLMModel.java:547)\n\tat hex.glm.GLM.getNullBeta(GLM.java:359)\n\tat hex.glm.GLM.init(GLM.java:502)\n\tat hex.glm.GLM$GLMDriver.computeImpl(GLM.java:1149)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\n\tat hex.glm.GLM$GLMDriver.compute2(GLM.java:569)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_feat_3 = H2OGeneralizedLinearEstimator(family='binomial', model_id='glm_v6', lambda_search=True)\n",
    "glm_binom_feat_3.train(covtype_X, covtype_y, training_frame=train_bf, validation_frame=valid_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-18adc0a58428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglm_binom_feat_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OGeneralizedLinearEstimator' has no attribute 'accuracy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "glm_binom_feat_3.accuracy(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n",
      "Interactions progress: |██████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_f, valid_f, test_f = add_features(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_multi_v3 = H2OGeneralizedLinearEstimator(\n",
    "                        model_id='glm_v7',           \n",
    "                        family='multinomial',\n",
    "                        solver='L_BFGS',\n",
    "                        Lambda=0.0001)\n",
    "glm_multi_v3.train(covtype_X, covtype_y, training_frame=train_f, validation_frame=valid_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  glm_v7\n",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.20567994255054234\n",
      "RMSE: 0.4535195062514316\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.20678926805660505\n",
      "RMSE: 0.4547408801247201\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>490244.3713397</td>\n",
       "<td>1.2048958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.287 sec</td>\n",
       "<td>1</td>\n",
       "<td>390140.1633429</td>\n",
       "<td>0.9589602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.412 sec</td>\n",
       "<td>2</td>\n",
       "<td>364664.5843174</td>\n",
       "<td>0.8964480</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.660 sec</td>\n",
       "<td>3</td>\n",
       "<td>340164.2226989</td>\n",
       "<td>0.8364886</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:29</td>\n",
       "<td> 0.954 sec</td>\n",
       "<td>4</td>\n",
       "<td>323662.6690375</td>\n",
       "<td>0.7962510</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:42</td>\n",
       "<td>14.677 sec</td>\n",
       "<td>55</td>\n",
       "<td>256380.3518102</td>\n",
       "<td>0.6394377</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:43</td>\n",
       "<td>14.924 sec</td>\n",
       "<td>56</td>\n",
       "<td>256248.8448666</td>\n",
       "<td>0.6393366</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:43</td>\n",
       "<td>15.619 sec</td>\n",
       "<td>57</td>\n",
       "<td>256152.1928321</td>\n",
       "<td>0.6392126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:44</td>\n",
       "<td>15.956 sec</td>\n",
       "<td>58</td>\n",
       "<td>256046.5582918</td>\n",
       "<td>0.6391381</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:44</td>\n",
       "<td>16.277 sec</td>\n",
       "<td>59</td>\n",
       "<td>256037.8827738</td>\n",
       "<td>0.6390779</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "---  -------------------  ----------  ------------  -------------------------  ------------------\n",
       "     2018-03-14 16:44:28  0.000 sec   0             490244.3713396542          1.2048957580292183\n",
       "     2018-03-14 16:44:28  0.287 sec   1             390140.16334289697         0.9589602445089822\n",
       "     2018-03-14 16:44:28  0.412 sec   2             364664.5843174079          0.8964479683099776\n",
       "     2018-03-14 16:44:28  0.660 sec   3             340164.2226989407          0.836488550598829\n",
       "     2018-03-14 16:44:29  0.954 sec   4             323662.66903745953         0.796250985568061\n",
       "---  ---                  ---         ---           ---                        ---\n",
       "     2018-03-14 16:44:42  14.677 sec  55            256380.35181021446         0.6394376718160981\n",
       "     2018-03-14 16:44:43  14.924 sec  56            256248.8448666195          0.6393366229375401\n",
       "     2018-03-14 16:44:43  15.619 sec  57            256152.19283213865         0.6392125840169233\n",
       "     2018-03-14 16:44:44  15.956 sec  58            256046.55829182628         0.6391380841735504\n",
       "     2018-03-14 16:44:44  16.277 sec  59            256037.8827737812          0.6390779382942982"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7235651</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.967752</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9939686</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9982768</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9997358</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999885</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.723565\n",
       "2    0.967752\n",
       "3    0.993969\n",
       "4    0.998277\n",
       "5    0.999736\n",
       "6    0.999988\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v3.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>class_1</b></td>\n",
       "<td><b>class_2</b></td>\n",
       "<td><b>class_3</b></td>\n",
       "<td><b>class_4</b></td>\n",
       "<td><b>class_5</b></td>\n",
       "<td><b>class_6</b></td>\n",
       "<td><b>class_7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>22089.0</td>\n",
       "<td>8963.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>624.0</td>\n",
       "<td>0.3029002</td>\n",
       "<td>9,598 / 31,687</td></tr>\n",
       "<tr><td>7673.0</td>\n",
       "<td>33990.0</td>\n",
       "<td>507.0</td>\n",
       "<td>2.0</td>\n",
       "<td>31.0</td>\n",
       "<td>226.0</td>\n",
       "<td>24.0</td>\n",
       "<td>0.1993499</td>\n",
       "<td>8,463 / 42,453</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>537.0</td>\n",
       "<td>4334.0</td>\n",
       "<td>80.0</td>\n",
       "<td>2.0</td>\n",
       "<td>360.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1842650</td>\n",
       "<td>979 / 5,313</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>220.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.0</td>\n",
       "<td>66.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6620370</td>\n",
       "<td>286 / 432</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>1363.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0</td>\n",
       "<td>34.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9765355</td>\n",
       "<td>1,415 / 1,449</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>633.0</td>\n",
       "<td>1308.0</td>\n",
       "<td>5.0</td>\n",
       "<td>7.0</td>\n",
       "<td>645.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7517321</td>\n",
       "<td>1,953 / 2,598</td></tr>\n",
       "<tr><td>1338.0</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1744.0</td>\n",
       "<td>0.4395887</td>\n",
       "<td>1,368 / 3,112</td></tr>\n",
       "<tr><td>31104.0</td>\n",
       "<td>45516.0</td>\n",
       "<td>6406.0</td>\n",
       "<td>233.0</td>\n",
       "<td>74.0</td>\n",
       "<td>1319.0</td>\n",
       "<td>2392.0</td>\n",
       "<td>0.2764349</td>\n",
       "<td>24,062 / 87,044</td></tr></table></div>"
      ],
      "text/plain": [
       "class_1    class_2    class_3    class_4    class_5    class_6    class_7    Error     Rate\n",
       "---------  ---------  ---------  ---------  ---------  ---------  ---------  --------  ---------------\n",
       "22089      8963       1          0          0          10         624        0.3029    9,598 / 31,687\n",
       "7673       33990      507        2          31         226        24         0.19935   8,463 / 42,453\n",
       "0          537        4334       80         2          360        0          0.184265  979 / 5,313\n",
       "0          0          220        146        0          66         0          0.662037  286 / 432\n",
       "4          1363       36         0          34         12         0          0.976536  1,415 / 1,449\n",
       "0          633        1308       5          7          645        0          0.751732  1,953 / 2,598\n",
       "1338       30         0          0          0          0          1744       0.439589  1,368 / 3,112\n",
       "31104      45516      6406       233        74         1319       2392       0.276435  24,062 / 87,044"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v3.confusion_matrix(valid_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  glm_v7\n",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.20567994255054234\n",
      "RMSE: 0.4535195062514316\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.20678926805660505\n",
      "RMSE: 0.4547408801247201\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>490244.3713397</td>\n",
       "<td>1.2048958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.287 sec</td>\n",
       "<td>1</td>\n",
       "<td>390140.1633429</td>\n",
       "<td>0.9589602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.412 sec</td>\n",
       "<td>2</td>\n",
       "<td>364664.5843174</td>\n",
       "<td>0.8964480</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:28</td>\n",
       "<td> 0.660 sec</td>\n",
       "<td>3</td>\n",
       "<td>340164.2226989</td>\n",
       "<td>0.8364886</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:29</td>\n",
       "<td> 0.954 sec</td>\n",
       "<td>4</td>\n",
       "<td>323662.6690375</td>\n",
       "<td>0.7962510</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:42</td>\n",
       "<td>14.677 sec</td>\n",
       "<td>55</td>\n",
       "<td>256380.3518102</td>\n",
       "<td>0.6394377</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:43</td>\n",
       "<td>14.924 sec</td>\n",
       "<td>56</td>\n",
       "<td>256248.8448666</td>\n",
       "<td>0.6393366</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:43</td>\n",
       "<td>15.619 sec</td>\n",
       "<td>57</td>\n",
       "<td>256152.1928321</td>\n",
       "<td>0.6392126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:44</td>\n",
       "<td>15.956 sec</td>\n",
       "<td>58</td>\n",
       "<td>256046.5582918</td>\n",
       "<td>0.6391381</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-03-14 16:44:44</td>\n",
       "<td>16.277 sec</td>\n",
       "<td>59</td>\n",
       "<td>256037.8827738</td>\n",
       "<td>0.6390779</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "---  -------------------  ----------  ------------  -------------------------  ------------------\n",
       "     2018-03-14 16:44:28  0.000 sec   0             490244.3713396542          1.2048957580292183\n",
       "     2018-03-14 16:44:28  0.287 sec   1             390140.16334289697         0.9589602445089822\n",
       "     2018-03-14 16:44:28  0.412 sec   2             364664.5843174079          0.8964479683099776\n",
       "     2018-03-14 16:44:28  0.660 sec   3             340164.2226989407          0.836488550598829\n",
       "     2018-03-14 16:44:29  0.954 sec   4             323662.66903745953         0.796250985568061\n",
       "---  ---                  ---         ---           ---                        ---\n",
       "     2018-03-14 16:44:42  14.677 sec  55            256380.35181021446         0.6394376718160981\n",
       "     2018-03-14 16:44:43  14.924 sec  56            256248.8448666195          0.6393366229375401\n",
       "     2018-03-14 16:44:43  15.619 sec  57            256152.19283213865         0.6392125840169233\n",
       "     2018-03-14 16:44:44  15.956 sec  58            256046.55829182628         0.6391380841735504\n",
       "     2018-03-14 16:44:44  16.277 sec  59            256037.8827737812          0.6390779382942982"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2o.shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
